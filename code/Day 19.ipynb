{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code - Day 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For heaven's sake. I lose my prolog-running machine, and suddenly all the problems are about writing parsers.\n",
    "\n",
    "Haven't done this for a bit, but let's try writing a recursive descent parser..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rats, version I'm using doesn't have pyrsistent. Get ready for lots of copying..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rule(str_in):\n",
    "    m=re.match('(\\d+):(.+)', str_in)\n",
    "    \n",
    "    return (int(m.group(1)),\n",
    "            [[int(r) if r.isnumeric() else r.strip('\"\"')\n",
    "              for r in rhs.split()]\n",
    "             for rhs in m.group(2).split('|')])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input(str_in):\n",
    "    \n",
    "    [grammar, inputs]=str_in.split('\\n\\n')\n",
    "    \n",
    "    \n",
    "    return ({lhs:rhs for (lhs, rhs) in \n",
    "             [parse_rule(nl) for nl in grammar.splitlines()]},\n",
    "            \n",
    "            [list(nl) for nl in inputs.splitlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [[4, 1, 5]],\n",
       " 1: [[2, 3], [3, 2]],\n",
       " 2: [[4, 4], [5, 5]],\n",
       " 3: [[4, 5], [5, 4]],\n",
       " 4: [['a']],\n",
       " 5: [['b']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(grammar, inputs_ls)=parse_input(open('data/day19_test').read())\n",
    "grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'b', 'a', 'b', 'b', 'b'],\n",
       " ['b', 'a', 'b', 'a', 'b', 'a'],\n",
       " ['a', 'b', 'b', 'b', 'a', 'b'],\n",
       " ['a', 'a', 'a', 'b', 'b', 'b'],\n",
       " ['a', 'a', 'a', 'a', 'b', 'b', 'b']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agenda(start, input_tokens, grammar):\n",
    "    return [([start], input_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_states(state_in, grammar):\n",
    "\n",
    "    (tree, tokens)=state_in\n",
    "    next_states=[]\n",
    "    \n",
    "    if not (tree and tokens):\n",
    "        return next_states\n",
    "    \n",
    "    if tree[0]==tokens[0]:\n",
    "            next_states.append((tree[1:].copy(),\n",
    "                                tokens[1:].copy()))\n",
    "    \n",
    "    if isinstance(tree[0], int):\n",
    "        for rhs in grammar[tree[0]]:\n",
    "            rhscopy=rhs.copy()\n",
    "            rhscopy.extend(tree[1:].copy())\n",
    "            next_states.append((rhscopy, tokens.copy()))\n",
    "    \n",
    "    return next_states\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_state(state_in):\n",
    "    \n",
    "    return state_in==([], [])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise(tokens_ls, grammar):\n",
    "\n",
    "    agenda=build_agenda(0, tokens_ls, grammar)\n",
    "    \n",
    "    while agenda:\n",
    "        \n",
    "        state=agenda.pop(0)\n",
    "        \n",
    "        if final_state(state):\n",
    "            return True\n",
    "        \n",
    "        agenda[0:0]=next_states(state, grammar)\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day19_part1(file_in):\n",
    "    \n",
    "    (grammar, inputs_ls)=parse_input(open(file_in).read())\n",
    "    \n",
    "    return [tokens_ls for tokens_ls in inputs_ls\n",
    "            if recognise(tokens_ls, grammar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(day19_part1('data/day19_test')) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(day19_part1('data/day19_input'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a horrible moment, I thought I was going to have to convert my parser to run bottom up. But no! The rules aren't left recursive, so should be a problem.\n",
    "\n",
    "Finally, get some benefits from doing Part 1 properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(day19_part1('data/day19_testb'))==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(day19_part1('data/day19_testc'))==12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(day19_part1('data/day19_inputb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
